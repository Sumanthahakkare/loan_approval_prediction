# -*- coding: utf-8 -*-
"""loan approval prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ij6kOHJfMyo3sRSYTw8PVZPY17xmAATK
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv('/content/Dataset.csv')



df.isnull().sum()

df.columns

df.info()

plt.figure(figsize=(12,8))
sns.boxplot(data=df)

#fill null value to loan ammount preffer median because its not effected by outlier
df['LoanAmount']=df['LoanAmount'].fillna(df['LoanAmount'].median())
df['Loan_Amount_Term']=df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mean())
df['Credit_History']=df['Credit_History'].fillna(df['Credit_History'].mean())

(df['Gender'].mode()[0])

df['Gender']=df['Gender'].fillna(df['Gender'].mode()[0])
df['Married']=df['Married'].fillna(df['Married'].mode()[0])
df['Dependents']=df['Dependents'].fillna(df['Dependents'].mode()[0])
df['Self_Employed']=df['Self_Employed'].fillna(df['Self_Employed'].mode()[0])

df.isnull().sum()

#chacking number of male female checking class imbalance
df['Gender'].value_counts()
sns.countplot(x='Gender',data=df,palette='Set1')

df['Married'].value_counts()
sns.countplot(x='Married',data=df,palette='Set1')

df['Education'].value_counts()
sns.countplot(x='Education',data=df,palette='Set1')

numeric_df = df.select_dtypes(include=np.number)
corr = numeric_df.corr()

plt.figure(figsize=(12,8))
sns.heatmap(corr,annot=True,cmap='coolwarm')

df['Total_income']=df['ApplicantIncome']+df['CoapplicantIncome']

df.head()

df['ApplicantIncomelog']=np.log(df['ApplicantIncome'])
sns.distplot(df['ApplicantIncomelog'])

df['loan_amount_log']=np.log(df['LoanAmount'])
sns.distplot(df['loan_amount_log'])

df['Total_incomelog']=np.log(df['Total_income'])
sns.distplot(df['Total_incomelog'])

df['Loan_Amount_Termlog']=np.log(df['Loan_Amount_Term']+1)
sns.distplot(df['Loan_Amount_Termlog'])

df.head()

cols=['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','Total_income']
df=df.drop(columns=cols,axis=1)

df.head()

df=df.drop(columns='Loan_ID',axis=1)

#encoding
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
col=['Gender','Married','Dependents','Education','Self_Employed','Property_Area','Loan_Status']
for i in col:
  df[i]=le.fit_transform(df[i])

df.head()

df.info()

X=df.drop(columns='Loan_Status',axis=1)
y=df['Loan_Status']

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)

model=LogisticRegression()
model.fit(X_train,y_train)
y_pred=model.predict(X_test)
print(f'accuracy of logistic regression:{accuracy_score(y_test,y_pred)*100}')
print(confusion_matrix(y_test,y_pred))

from sklearn.model_selection import cross_val_score
score=cross_val_score(model,X,y,cv=5)
print(f'cross validation score of logistic regression:{np.mean(score)*100}')

model2=DecisionTreeClassifier()
model2.fit(X_train,y_train)
y_pred2=model2.predict(X_test)
print(f'accuracy of decisiontree model:{accuracy_score(y_test,y_pred2)*100}')
print(confusion_matrix(y_test,y_pred))

score=cross_val_score(model2,X,y,cv=5)
print(f'cross validation score of decisiontree model:{np.mean(score)*100}')

model3=RandomForestClassifier()
model3.fit(X_train,y_train)
y_pred3=model3.predict(X_test)
print(f'accuracy of random forest:{accuracy_score(y_test,y_pred3)*100}')
print(confusion_matrix(y_test,y_pred))

model4=KNeighborsClassifier(n_neighbors=6)
model4.fit(X_train,y_train)
y_pred4=model4.predict(X_test)
print(f'accuracy of KNN:{accuracy_score(y_test,y_pred4)*100}')

score=cross_val_score(model4,X,y,cv=5)
print(f'cross validation score of KNN:{np.mean(score)*100}')

df['Loan_Status'].value_counts()

pip install -U imbalanced-learn

from imblearn.over_sampling import RandomOverSampler

oversample=RandomOverSampler(random_state=42)
X_over,y_over=oversample.fit_resample(X,y)

df_resample=pd.concat([pd.DataFrame(X_over,columns=X.columns)
,pd.Series(y_over,name='loan_status')],axis=1)

X_over

y_over

y_over.value_counts()

X_resample_train,X_resample_test,y_resample_train,y_resample_test= \
train_test_split(X_over,y_over,test_size=0.25,random_state=42)

model5=LogisticRegression()
model5.fit(X_resample_train,y_resample_train)
y_pred5=model5.predict(X_resample_test)
print(f'accuracy of logistic regression:{accuracy_score(y_resample_test,y_pred5)*100}')
print(classification_report(y_resample_test, y_pred5))

model6=DecisionTreeClassifier()
model6.fit(X_resample_train,y_resample_train)
y_pred6=model6.predict(X_resample_test)
print(f'accuracy of logistic regression:{accuracy_score(y_resample_test,y_pred6)*100}')
print(classification_report(y_resample_test, y_pred6))

from sklearn.metrics import classification_report
model7=RandomForestClassifier()
model7.fit(X_resample_train,y_resample_train)
y_pred7=model7.predict(X_resample_test)
print(f'RandomForestClassifier:{accuracy_score(y_resample_test,y_pred7)*100}')
print(classification_report(y_resample_test, y_pred7))

model8=KNeighborsClassifier(n_neighbors=6)
model8.fit(X_resample_train,y_resample_train)
y_pred8=model8.predict(X_resample_test)
print(f'accuracy of KNN:{accuracy_score(y_resample_test,y_pred8)*100}')
print(classification_report(y_resample_test, y_pred8))





